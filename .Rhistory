geom_point(alpha = 0.6) +
labs(title = "K-means Clusters on PCA Space") +
theme_minimal()
# Scale numeric data for modeling
churn_data_scaled <- churn_data %>%
mutate(across(where(is.numeric), scale))
# Dataset summary
summary_report <- function(df) {
cat("==== Dataset Summary ====\n")
cat("Dimensions: ", dim(df), "\n\n")
cat("Missing Data Summary:\n")
check_missing(df)
cat("\nNear-zero Variance Variables:\n")
print(nearZeroVar(df))
cat("\nNumeric Variable Summary:\n")
print(summary(select(df, where(is.numeric))))
cat("\nTarget Variable Distribution:\n")
print(table(df$churn))
cat("\nskimr Detailed Summary:\n")
print(skim(df))
cat("=========================\n")
}
summary_report(churn_data)
# Final target variable visualization
ggplot(churn_data, aes(x = churn)) +
geom_bar(fill = c("blue", "orange")) +
labs(title = "Churn Distribution", x = "Churn", y = "Count") +
theme_minimal()
# Ensure model.matrix consistency across train and test sets
set.seed(42)
train_index <- createDataPartition(churn_data$churn, p = 0.8, list = FALSE)
train_data <- churn_data[train_index, ]
test_data <- churn_data[-train_index, ]
# Create consistent model formula
model_formula <- churn ~ .
# Create x and y matrices
x_train <- model.matrix(model_formula, data = train_data)[, -1]
x_test <- model.matrix(model_formula, data = test_data)[, -1]
y_train <- train_data$churn
y_test <- test_data$churn
# CRISP-DM Step 4: Modeling
set.seed(123)
repeat {
train_index <- createDataPartition(churn_data$churn, p = 0.8, list = FALSE)
train_data <- churn_data[train_index, ]
test_data <- churn_data[-train_index, ]
# Recode churn to "Yes"/"No" early
train_data$churn <- factor(ifelse(train_data$churn == 1, "Yes", "No"),
levels = c("No", "Yes"))
test_data$churn <- factor(ifelse(test_data$churn == 1, "Yes", "No"),
levels = c("No", "Yes"))
if (length(unique(test_data$churn)) == 2) break
}
for (col in names(train_data)) {
if (is.factor(train_data[[col]]) || is.character(train_data[[col]])) {
levels_union <- union(levels(factor(train_data[[col]])),
levels(factor(test_data[[col]])))
train_data[[col]] <- factor(train_data[[col]], levels = levels_union)
test_data[[col]] <- factor(test_data[[col]], levels = levels_union)
}
}
x_train <- model.matrix(churn ~ ., data = train_data)[, -1]
x_test <- model.matrix(churn ~ ., data = test_data)[, -1]
identical(colnames(x_train), colnames(x_test))  # should return TRUE
# Create model matrices for GLMNET and XGBoost
x_train <- model.matrix(churn ~ ., data = train_data)[, -1]
y_train <- train_data$churn
x_test <- model.matrix(churn ~ ., data = test_data)[, -1]
y_test <- test_data$churn
# GLMNET Model
model_glmnet <- cv.glmnet(x_train, y_train, family = "binomial",
type.measure = "class")
# Random Forest Model
model_rf <- randomForest(churn ~ ., data = train_data, ntree = 100)
# XGBoost Model
train_matrix <- xgb.DMatrix(data = x_train, label = as.numeric(y_train) - 1)
test_matrix <- xgb.DMatrix(data = x_test)
model_xgb <- xgboost(
data = train_matrix,
objective = "binary:logistic",
nrounds = 100,
verbose = 0
)
# CRISP-DM Step 5: Model Evaluation
## GLMNET Evaluation
probs_glmnet <- predict(model_glmnet, newx = x_test, type = "response",
s = "lambda.min") |> as.vector()
preds_glmnet <- ifelse(probs_glmnet > 0.5, "Yes", "No") |>
factor(levels = c("No", "Yes"))
# Ensure predicted factor levels match test labels
preds_glmnet <- factor(preds_glmnet, levels = levels(test_data$churn))
# Confusion matrix call
conf_matrix_glmnet <- confusionMatrix(preds_glmnet, test_data$churn,
positive = "Yes")
print(conf_matrix_glmnet)
roc_glmnet <- roc(response = test_data$churn, predictor = probs_glmnet,
levels = c("No", "Yes"))
auc_glmnet <- auc(roc_glmnet)
cat("AUC (GLMNET):", auc_glmnet, "\n")
## Random Forest Evaluation
probs_rf <- predict(model_rf, test_data, type = "prob")[, "Yes"]
preds_rf <- predict(model_rf, test_data)
conf_matrix_rf <- confusionMatrix(preds_rf, test_data$churn, positive = "Yes")
print(conf_matrix_rf)
roc_rf <- roc(response = test_data$churn, predictor = probs_rf,
levels = c("No", "Yes"))
auc_rf <- auc(roc_rf)
cat("AUC (Random Forest):", auc_rf, "\n")
## XGBoost Evaluation
probs_xgb <- predict(model_xgb, newdata = test_matrix)
preds_xgb <- ifelse(probs_xgb > 0.5, "Yes", "No") |> factor(levels =
c("No", "Yes"))
conf_matrix_xgb <- confusionMatrix(preds_xgb, test_data$churn, positive = "Yes")
print(conf_matrix_xgb)
roc_xgb <- roc(response = test_data$churn, predictor = probs_xgb,
levels = c("No", "Yes"))
auc_xgb <- auc(roc_xgb)
cat("AUC (XGBoost):", auc_xgb, "\n")
# ROC Curve Overlay
plot(roc_glmnet, col = "#2c7bb6", lwd = 2, main = "ROC Curves - All Models")
plot(roc_rf, col = "#d7191c", lwd = 2, add = TRUE)
plot(roc_xgb, col = "#fdae61", lwd = 2, add = TRUE)
legend("bottomright", legend = c("GLMNET", "Random Forest", "XGBoost"),
col = c("#2c7bb6", "#d7191c", "#fdae61"), lwd = 2)
# Confusion Matrix Heatmaps
plot_cm <- function(conf_matrix, title) {
cm_df <- as.data.frame(conf_matrix$table)
ggplot(cm_df, aes(Prediction, Reference, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), color = "white", size = 5) +
scale_fill_gradient(low = "steelblue", high = "darkred") +
theme_minimal() +
labs(title = title, x = "Predicted", y = "Actual")
}
plot_cm(conf_matrix_glmnet, "Confusion Matrix - GLMNET")
plot_cm(conf_matrix_rf, "Confusion Matrix - Random Forest")
plot_cm(conf_matrix_xgb, "Confusion Matrix - XGBoost")
# 6. Deployment
# This script can be wrapped into an RMarkdown report, dashboard, or API
#service for end-user consumption.
# SETUP: prompt option and working directory
options(prompt = "R> ")
setwd("D:/Bill/SNHU/DAT650/DAT 650 Project")
# CRISP-DM Step 1: BUSINESS UNDERSTANDING
# Goal: Predict customer churn using behavioral, demographic, and account features
# CRISP-DM Step 2: DATA UNDERSTANDING
# Install required packages
required_packages <- c("tidyverse", "readr", "caret", "janitor", "naniar",
"forcats", "skimr", "GGally", "factoextra", "cluster",
"pROC", "randomForest", "glmnet", "e1071", "xgboost")
new_packages <- required_packages[!(required_packages %in%
installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load libraries
library(tidyverse)
library(readr)
library(caret)
library(janitor)
library(naniar)
library(forcats)
library(skimr)
library(GGally)
library(factoextra)
library(cluster)
library(pROC)
library(randomForest)
library(glmnet)
library(e1071)
library(xgboost)
# Load and clean data
churn_data <- read.csv("CustomerChurn_Data.csv") %>%
clean_names() %>%
mutate(churn = as.factor(churn)) %>%
select(-customer, -csa)
# Missing data check
check_missing <- function(df) {
missing_count <- sapply(df, function(x) sum(is.na(x)))
missing_pct <- sapply(df, function(x) mean(is.na(x)) * 100)
summary_df <- data.frame(
Variable = names(df),
MissingCount = missing_count,
MissingPercent = missing_pct
)
print(summary_df %>% filter(MissingCount > 0))
vis_miss(df)
}
cat("Missing data before imputation:\n")
check_missing(churn_data)
# Impute missing values
churn_data <- churn_data %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.),
median(., na.rm = TRUE), .))) %>%
mutate(across(where(is.factor),
~ forcats::fct_explicit_na(., na_level = "Missing")))
cat("Missing data after imputation:\n")
check_missing(churn_data)
# Remove near-zero variance predictors
remove_nzv <- function(df) {
nzv <- nearZeroVar(df)
if (length(nzv) > 0) {
cat("Removing near-zero variance variables:\n")
print(names(df)[nzv])
df <- df[, -nzv]
}
return(df)
}
churn_data <- remove_nzv(churn_data)
# Feature engineering
churn_data <- churn_data %>%
mutate(avg_custcare_calls_per_month = ifelse(months == 0, 0, custcare / months))
# PCA and K-means clustering
num_vars <- select(churn_data, where(is.numeric))
pca_res <- prcomp(num_vars, scale. = TRUE)
pca_df <- as.data.frame(pca_res$x) %>%
mutate(churn = churn_data$churn)
kmeans_res <- kmeans(scale(num_vars), centers = 3, nstart = 25)
churn_data$cluster <- as.factor(kmeans_res$cluster)
# Scale numeric variables
churn_data_scaled <- churn_data %>%
mutate(across(where(is.numeric), scale))
# Summary report
summary_report <- function(df) {
cat("==== Dataset Summary ====\n")
cat("Dimensions: ", dim(df), "\n\n")
check_missing(df)
cat("\nNear-zero Variance Variables:\n")
print(nearZeroVar(df))
cat("\nTarget Variable Distribution:\n")
print(table(df$churn))
cat("=========================\n")
}
summary_report(churn_data)
ggplot(churn_data, aes(x = churn)) +
geom_bar(fill = c("blue", "orange")) +
labs(title = "Churn Distribution", x = "Churn", y = "Count") +
theme_minimal()
# CRISP-DM Step 4: MODELING
# === Helper function for matrix alignment ===
create_model_matrix <- function(train_df, test_df, target_var) {
predictors <- setdiff(names(train_df), target_var)
for (var in predictors) {
if (is.character(train_df[[var]])) train_df[[var]] <- as.factor(train_df[[var]])
if (is.character(test_df[[var]]))  test_df[[var]]  <- as.factor(test_df[[var]])
}
for (var in predictors) {
if (is.factor(train_df[[var]])) {
test_df[[var]] <- factor(test_df[[var]], levels = levels(train_df[[var]]))
}
}
formula <- as.formula(paste("~", paste(predictors, collapse = "+"), "-1"))
x_train <- model.matrix(formula, data = train_df)
x_test  <- model.matrix(formula, data = test_df)
return(list(x_train = x_train, x_test = x_test))
}
# === Train-test split ===
set.seed(42)
train_index <- createDataPartition(churn_data$churn, p = 0.8, list = FALSE)
train_data <- churn_data[train_index, ]
test_data  <- churn_data[-train_index, ]
test_data$churn <- as.factor(test_data$churn)
# === Prepare matrices ===
model_matrices <- create_model_matrix(train_data, test_data, target_var = "churn")
x_train <- model_matrices$x_train
x_test  <- model_matrices$x_test
y_train <- as.numeric(as.character(train_data$churn))
# === LASSO Logistic Regression ===
set.seed(42)
cv_lasso <- cv.glmnet(x_train, y_train, family = "binomial", alpha = 1)
best_lambda <- cv_lasso$lambda.min
lasso_model <- glmnet(x_train, y_train, family = "binomial", alpha = 1, lambda = best_lambda)
lasso_probs <- predict(lasso_model, newx = x_test, type = "response")
lasso_pred <- ifelse(lasso_probs > 0.5, "1", "0") %>% as.factor()
# === Random Forest ===
set.seed(42)
rf_model <- randomForest(churn ~ ., data = train_data, ntree = 500, importance = TRUE)
rf_pred <- predict(rf_model, test_data, type = "response")
rf_prob <- predict(rf_model, test_data, type = "prob")[, 2]
# === XGBoost ===
set.seed(42)
xgb_train <- xgb.DMatrix(data = x_train, label = y_train)
xgb_test  <- xgb.DMatrix(data = x_test)
xgb_params <- list(
objective = "binary:logistic",
eval_metric = "auc",
max_depth = 6,
eta = 0.1,
nthread = 2
)
xgb_model <- xgb.train(params = xgb_params, data = xgb_train, nrounds = 100, verbose = 0)
xgb_prob <- predict(xgb_model, xgb_test)
xgb_pred <- ifelse(xgb_prob > 0.5, "1", "0") %>% as.factor()
# CRISP-DM Step 5: Evaluation
# === Confusion matrices ===
cat("\n--- Confusion Matrices ---\n")
cat("\nLASSO:\n"); print(table(Predicted = lasso_pred, Actual = test_data$churn))
cat("\nRandom Forest:\n"); print(table(Predicted = rf_pred, Actual = test_data$churn))
cat("\nXGBoost:\n"); print(table(Predicted = xgb_pred, Actual = test_data$churn))
# === Detailed metrics ===
lasso_cm <- confusionMatrix(lasso_pred, test_data$churn)
rf_cm    <- confusionMatrix(rf_pred, test_data$churn)
xgb_cm   <- confusionMatrix(xgb_pred, test_data$churn)
lasso_roc <- roc(test_data$churn, as.numeric(lasso_probs))
rf_roc    <- roc(test_data$churn, rf_prob)
xgb_roc   <- roc(test_data$churn, xgb_prob)
# === ROC plots ===
plot(lasso_roc, col = "darkred", lwd = 2, main = "ROC Comparison - All Models")
plot(rf_roc, col = "blue", lwd = 2, add = TRUE)
plot(xgb_roc, col = "darkgreen", lwd = 2, add = TRUE)
legend("bottomright", legend = c("LASSO", "Random Forest", "XGBoost"),
col = c("darkred", "blue", "darkgreen"), lwd = 2)
# === Comparison summary table ===
comparison_table <- tibble::tibble(
Model = c("LASSO Logistic", "Random Forest", "XGBoost"),
Accuracy = c(lasso_cm$overall["Accuracy"], rf_cm$overall["Accuracy"], xgb_cm$overall["Accuracy"]),
Precision = c(lasso_cm$byClass["Precision"], rf_cm$byClass["Precision"], xgb_cm$byClass["Precision"]),
Recall = c(lasso_cm$byClass["Recall"], rf_cm$byClass["Recall"], xgb_cm$byClass["Recall"]),
F1_Score = c(lasso_cm$byClass["F1"], rf_cm$byClass["F1"], xgb_cm$byClass["F1"]),
AUC = c(auc(lasso_roc), auc(rf_roc), auc(xgb_roc))
)
print(comparison_table)
# Reshape for plotting
library(reshape2)
comparison_long <- melt(comparison_table, id.vars = "Model",
variable.name = "Metric", value.name = "Value")
# Bar plot comparison
ggplot(comparison_long, aes(x = Model, y = Value, fill = Model)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~ Metric, scales = "free_y") +
labs(title = "Model Comparison Across Metrics",
x = "Model",
y = "Score") +
scale_fill_manual(values = c("LASSO Logistic" = "darkred",
"Random Forest" = "blue",
"XGBoost" = "darkgreen")) +
theme_minimal() +
theme(legend.position = "none",
strip.text = element_text(face = "bold"),
axis.text.x = element_text(angle = 45, hjust = 1))
# SETUP: prompt option and working directory
options(prompt = "R> ")
setwd("D:/Bill/SNHU/DAT650/DAT 650 Project")
# CRISP-DM Step 1: BUSINESS UNDERSTANDING
# Goal: Predict customer churn using behavioral, demographic, and account features
# Hypotheses:
# - Customers with low usage and long tenure are more likely to churn
# - Certain demographic segments may have higher churn risk
# CRISP-DM Step 2: DATA UNDERSTANDING
# Install required packages
required_packages <- c("tidyverse", "readr", "caret", "janitor", "naniar",
"forcats", "skimr", "GGally", "factoextra", "cluster")
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)
# Load libraries
library(tidyverse)
library(readr)
library(caret)
library(janitor)
library(naniar)
library(forcats)
library(skimr)
library(GGally)
library(factoextra)
library(cluster)
# Load data
churn_data <- read.csv("CustomerChurn_Data.csv")
# Initial data glimpse
glimpse(churn_data)
# Clean column names and factorize target variable
churn_data <- churn_data %>%
clean_names() %>%
mutate(churn = as.factor(churn))
# Drop high-cardinality or ID columns
churn_data <- churn_data %>%
select(-customer, -csa)
# Missing data check and visualization
check_missing <- function(df) {
missing_count <- sapply(df, function(x) sum(is.na(x)))
missing_pct <- sapply(df, function(x) mean(is.na(x)) * 100)
summary_df <- data.frame(
Variable = names(df),
MissingCount = missing_count,
MissingPercent = missing_pct
)
print(summary_df %>% filter(MissingCount > 0))
vis_miss(df)
}
cat("Missing data before imputation:\n")
check_missing(churn_data)
# Impute missing values
churn_data <- churn_data %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(where(is.factor), ~ {
f <- forcats::fct_na_value_to_level(.)
levels(f)[levels(f) == "NA"] <- "Missing"
f
}))
cat("\nMissing data after imputation:\n")
check_missing(churn_data)
# Remove near-zero variance predictors
remove_nzv <- function(df) {
nzv <- nearZeroVar(df)
if (length(nzv) > 0) {
cat("Removing near-zero variance variables:\n")
print(names(df)[nzv])
df <- df[, -nzv]
} else {
cat("No near-zero variance variables found.\n")
}
return(df)
}
churn_data <- remove_nzv(churn_data)
# Feature Engineering: derive service interaction per month
churn_data <- churn_data %>%
mutate(avg_custcare_calls_per_month = ifelse(months == 0, 0, custcare / months))
# Identify numeric and factor variables
num_vars <- select(churn_data, where(is.numeric))
cat_vars <- select(churn_data, where(is.factor))
# Correlation matrix for numeric variables
GGally::ggcorr(num_vars, label = TRUE, label_alpha = TRUE, name = "Correlation")
# Univariate numeric analysis
cat("\nSummary statistics for numeric variables:\n")
print(summary(num_vars))
num_vars %>%
pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "#1f77b4", color = "black") +
facet_wrap(~variable, scales = "free") +
theme_minimal() +
labs(title = "Histograms of Numeric Variables")
# Prepare data with churn for pairwise visualizations
num_with_churn <- churn_data %>%
select(where(is.numeric)) %>%
mutate(churn = churn_data$churn)
# Cleaned Scatterplot Matrix: Reduced warnings
vars_for_plot <- num_with_churn %>%
select(revenue, mou, overage, roam, dropvce, blckvce,
custcare, outcalls, incalls, age1, age2, income, churn)
GGally::ggpairs(data = vars_for_plot,
aes(color = churn)) +
theme_minimal() +
labs(title = "Scatterplot Matrix Colored by Churn")
# Univariate categorical analysis
for (var in names(cat_vars)) {
cat(sprintf("\nFrequency table for %s:\n", var))
print(table(cat_vars[[var]]))
print(
ggplot(churn_data, aes_string(x = var)) +
geom_bar(fill = "#ff7f0e") +
labs(title = paste("Bar Plot of", var)) +
theme_minimal()
)
}
# Outlier detection
detect_outliers <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
outliers <- x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR)
sum(outliers, na.rm = TRUE)
}
cat("\nOutlier counts by numeric variable:\n")
print(sapply(num_vars, detect_outliers))
# CRISP-DM Step 3: DATA PREPARATION
# Principal Component Analysis
pca_res <- prcomp(num_vars, scale. = TRUE)
summary(pca_res)
fviz_eig(pca_res) +
labs(title = "Scree Plot: Variance Explained by Principal Components")
pca_df <- as.data.frame(pca_res$x) %>%
mutate(churn = churn_data$churn)
ggplot(pca_df, aes(x = PC1, y = PC2, color = churn)) +
geom_point(alpha = 0.6) +
labs(title = "PCA Biplot Colored by Churn") +
theme_minimal()
# K-means clustering
set.seed(123)
num_scaled <- scale(num_vars)
fviz_nbclust(num_scaled, kmeans, method = "wss") +
labs(title = "Elbow Method for Optimal k")
k <- 3
kmeans_res <- kmeans(num_scaled, centers = k, nstart = 25)
churn_data$cluster <- as.factor(kmeans_res$cluster)
ggplot(pca_df, aes(x = PC1, y = PC2, color = churn_data$cluster)) +
geom_point(alpha = 0.6) +
labs(title = "K-means Clusters on PCA Space") +
theme_minimal()
# Scale numeric data for modeling
churn_data_scaled <- churn_data %>%
mutate(across(where(is.numeric), scale))
# Dataset summary
summary_report <- function(df) {
cat("==== Dataset Summary ====\n")
cat("Dimensions: ", dim(df), "\n\n")
cat("Missing Data Summary:\n")
check_missing(df)
cat("\nNear-zero Variance Variables:\n")
print(nearZeroVar(df))
cat("\nNumeric Variable Summary:\n")
print(summary(select(df, where(is.numeric))))
cat("\nTarget Variable Distribution:\n")
print(table(df$churn))
cat("\nskimr Detailed Summary:\n")
print(skim(df))
cat("=========================\n")
}
summary_report(churn_data)
# Final target variable visualization
ggplot(churn_data, aes(x = churn)) +
geom_bar(fill = c("blue", "orange")) +
labs(title = "Churn Distribution", x = "Churn", y = "Count") +
theme_minimal()
q()
